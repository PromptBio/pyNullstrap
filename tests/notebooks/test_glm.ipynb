{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb0f9a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: X=(500, 100), y=(500,)\n",
      "True signal indices: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "Number of true signals: 20\n",
      "y distribution: 246 ones out of 500 samples (0.492 proportion)\n",
      "Linear predictor range: [-5.540, 4.820]\n",
      "Probability range: [0.004, 0.992]\n"
     ]
    }
   ],
   "source": [
    "# R to Python conversion of GLM simulation setup\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Set parameters (matching R code exactly)\n",
    "n = 500\n",
    "p = 100\n",
    "nonzero_coefs = 20\n",
    "Amp = 9\n",
    "rho = 0.6\n",
    "\n",
    "# Generate Toeplitz correlation matrix (equivalent to toeplitz(rho^(0:(p-1))))\n",
    "Theta_8 = np.array([[rho**abs(i-j) for j in range(p)] for i in range(p)])\n",
    "\n",
    "# Generate X from multivariate normal (equivalent to mvrnorm)\n",
    "X = multivariate_normal.rvs(mean=np.zeros(p), cov=Theta_8, size=n, random_state=42)\n",
    "\n",
    "# Scale X with 1/sqrt(n) factor (equivalent to scale(X)/(sqrt(n)))\n",
    "X = StandardScaler().fit_transform(X) / np.sqrt(n)\n",
    "\n",
    "# Generate true coefficients (equivalent to beta setup)\n",
    "beta = np.zeros(p)\n",
    "beta[:nonzero_coefs] = np.random.choice([-Amp, Amp], size=nonzero_coefs, replace=True)\n",
    "\n",
    "# Signal indices (equivalent to Signal_index <- 1:nonzero_coefs)\n",
    "Signal_index = np.arange(nonzero_coefs)  # 0-indexed in Python vs 1-indexed in R\n",
    "\n",
    "# True labels (equivalent to true_labels <- beta != 0)\n",
    "true_labels = beta != 0\n",
    "\n",
    "# Generate linear predictor (equivalent to linear_predictor <- X %*% beta)\n",
    "linear_predictor = X @ beta\n",
    "\n",
    "# Generate probabilities using logistic function (equivalent to prob <- 1 / (1 + exp(-linear_predictor)))\n",
    "prob = 1 / (1 + np.exp(-linear_predictor))\n",
    "\n",
    "# Generate binary response (equivalent to y <- rbinom(n, 1, prob))\n",
    "y = np.random.binomial(1, prob, n)\n",
    "\n",
    "print(f\"Data shape: X={X.shape}, y={y.shape}\")\n",
    "print(f\"True signal indices: {Signal_index}\")\n",
    "print(f\"Number of true signals: {np.sum(true_labels)}\")\n",
    "print(f\"y distribution: {np.sum(y)} ones out of {n} samples ({np.mean(y):.3f} proportion)\")\n",
    "print(f\"Linear predictor range: [{np.min(linear_predictor):.3f}, {np.max(linear_predictor):.3f}]\")\n",
    "print(f\"Probability range: [{np.min(prob):.3f}, {np.max(prob):.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d31eb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 3.752759457568664\n",
      "Selected features: [ 0  1  2  3  4  6 11 12 17 18 96]\n",
      "Number selected: 11\n",
      "Correction factor: 1.377604161270841\n",
      "Alpha used: 0.7187627327609252\n"
     ]
    }
   ],
   "source": [
    "from nullstrap.models.glm import NullstrapGLM\n",
    "\n",
    "# After the simulation code above...\n",
    "\n",
    "# Initialize Nullstrap GLM\n",
    "model = NullstrapGLM(\n",
    "    fdr=0.1,           # Target FDR\n",
    "    alpha_=None,       # Auto-select alpha (regularization parameter)\n",
    "    B_reps=5,          # Bootstrap repetitions\n",
    "    family=\"binomial\", # GLM family\n",
    "    random_state=42    # For reproducibility\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# Get results\n",
    "threshold = model.threshold_\n",
    "selected_features = model.selected_\n",
    "statistics = model.statistic_\n",
    "correction_factor = model.correction_factor_\n",
    "alpha_used = model.alpha_used_\n",
    "\n",
    "print(f\"Threshold: {threshold}\")\n",
    "print(f\"Selected features: {selected_features}\")\n",
    "print(f\"Number selected: {len(selected_features)}\")\n",
    "print(f\"Correction factor: {correction_factor}\")\n",
    "print(f\"Alpha used: {alpha_used}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1728a035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic selected features: [ 0  1  2  3  4  6  7  8 10 11 12 16 17 18 19 20 23 28 29 30 32 34 36 38\n",
      " 41 42 44 46 58 61 66 72 75 79 85 87 91 96]\n",
      "Number selected by Logistic: 38\n",
      "Logistic C (1/lambda) used: 2.782559402207126\n",
      "Logistic lambda used: 0.3593813663804626\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "import numpy as np\n",
    "\n",
    "# Fit Logistic Regression with cross-validation to select lambda\n",
    "logistic = LogisticRegressionCV(\n",
    "    cv=5, \n",
    "    penalty='l1', \n",
    "    solver='liblinear',\n",
    "    fit_intercept=False,\n",
    "    random_state=42\n",
    ").fit(X, y)\n",
    "\n",
    "# Get the coefficients\n",
    "logistic_coef = logistic.coef_.flatten()\n",
    "\n",
    "# Select features with nonzero coefficients\n",
    "logistic_selected = np.where(logistic_coef != 0)[0]\n",
    "\n",
    "print(f\"Logistic selected features: {logistic_selected}\")\n",
    "print(f\"Number selected by Logistic: {len(logistic_selected)}\")\n",
    "print(f\"Logistic C (1/lambda) used: {logistic.C_[0]}\")\n",
    "print(f\"Logistic lambda used: {1.0 / logistic.C_[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8be3050a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nullstrap GLM Power: 0.500\n",
      "Nullstrap GLM FDR: 0.091\n",
      "Logistic Power: 0.750\n",
      "Logistic FDR: 0.605\n",
      "\n",
      "Class distribution: 246/500 positive cases (0.492 proportion)\n",
      "True positive rate: 10/20 true signals selected\n",
      "False positive rate: 1/11 selected features are false positives\n"
     ]
    }
   ],
   "source": [
    "from nullstrap.utils.metrics import compute_power, compute_fdr\n",
    "\n",
    "# Compute true support\n",
    "true_support = np.where(beta != 0)[0]\n",
    "\n",
    "# Nullstrap GLM results\n",
    "nullstrap_power = compute_power(selected_features, true_support)\n",
    "nullstrap_fdr = compute_fdr(selected_features, true_support, p) \n",
    "print(f\"Nullstrap GLM Power: {nullstrap_power:.3f}\")\n",
    "print(f\"Nullstrap GLM FDR: {nullstrap_fdr:.3f}\")\n",
    "\n",
    "# Logistic Regression results\n",
    "logistic_power = compute_power(logistic_selected, true_support)\n",
    "logistic_fdr = compute_fdr(logistic_selected, true_support, p)\n",
    "print(f\"Logistic Power: {logistic_power:.3f}\")\n",
    "print(f\"Logistic FDR: {logistic_fdr:.3f}\")\n",
    "\n",
    "# Additional GLM-specific metrics\n",
    "print(f\"\\nClass distribution: {np.sum(y)}/{n} positive cases ({np.mean(y):.3f} proportion)\")\n",
    "print(f\"True positive rate: {np.sum(selected_features < nonzero_coefs)}/{nonzero_coefs} true signals selected\")\n",
    "print(f\"False positive rate: {np.sum(selected_features >= nonzero_coefs)}/{len(selected_features)} selected features are false positives\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74005a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
